{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0MBjYcpE4v0",
        "outputId": "731606a9-ddc6-4770-a302-9bd09119b0ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.11/dist-packages (2.6.2.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "fatal: destination path 'language_models' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow tensorboardX\n",
        "!git clone https://github.com/GuyKabiri/language_models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import sys\n",
        "\n",
        "print(\"Available GPUs:\", tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "import tensorflow.keras as keras\n",
        "sys.modules['keras'] = keras\n",
        "\n",
        "if \"language_models\" not in sys.path:\n",
        "    sys.path.append(\"language_models\")\n",
        "\n",
        "print(\"Keras version:\", keras.__version__)"
      ],
      "metadata": {
        "id": "9KJtpj2DG6rB",
        "outputId": "25e45bd7-0fbd-4dee-c557-d5f86cfb8122",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available GPUs: []\n",
            "Keras version: 3.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BunjCG5NE7HT",
        "outputId": "444c723b-357c-41f2-fd21-59c7c83c1f79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available GPUs: []\n"
          ]
        }
      ],
      "source": [
        "import sys, types\n",
        "import tensorflow as tf\n",
        "\n",
        "# ודא שה-GPU זמין\n",
        "print(\"Available GPUs:\", tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "# מיפוי מודולי keras ל-tf.keras\n",
        "sys.modules['keras'] = types.ModuleType('keras')\n",
        "sys.modules['keras.preprocessing.text'] = tf.keras.preprocessing.text\n",
        "sys.modules['keras.preprocessing.sequence'] = tf.keras.preprocessing.sequence\n",
        "sys.modules['keras.layers'] = tf.keras.layers\n",
        "sys.modules['keras.utils'] = tf.keras.utils\n",
        "sys.modules['keras.backend'] = tf.keras.backend\n",
        "\n",
        "# הוספת ספריית language_models לנתיב\n",
        "if \"language_models\" not in sys.path:\n",
        "    sys.path.append(\"language_models\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import sys\n",
        "\n",
        "# מיפוי מודול keras ל-tf.keras\n",
        "sys.modules['keras'] = keras\n",
        "sys.modules['keras.preprocessing'] = keras.preprocessing\n",
        "sys.modules['keras.preprocessing.sequence'] = keras.preprocessing.sequence\n",
        "\n",
        "print(\"Keras version:\", keras.__version__)\n",
        "print(\"Available GPUs:\", tf.config.list_physical_devices('GPU'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBFVEZeMH3yN",
        "outputId": "e54bb576-4f7f-4807-cc81-0a45ff9754ad"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keras version: 3.8.0\n",
            "Available GPUs: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "wYEd5HFbE9Ih"
      },
      "outputs": [],
      "source": [
        "import scipy\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding, Input, TimeDistributed\n",
        "from tensorboardX import SummaryWriter\n",
        "from tqdm import tqdm\n",
        "\n",
        "from language_models import util"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "bCt27eNAE-29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60e91a5e-101c-412a-d094-fd273276a084"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "raw data read\n",
            "max length per batch:  [15, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 27, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 31, 31, 31, 31, 32, 32, 32, 32, 32, 33, 33, 33, 34, 34, 34, 35, 35, 35, 36, 36, 36, 37, 38, 38, 39, 39, 40, 41, 42, 42, 44, 45, 46, 47, 49, 52, 55, 62, 133]\n",
            "max length per batch:  [17, 18, 19, 19, 20, 20, 21, 21, 22, 22, 23, 24, 24, 25, 26, 27, 28, 30, 31, 33, 36, 41, 55, 133]\n",
            "max length per batch:  [17, 18, 19, 19, 20, 20, 21, 21, 22, 23, 23, 24, 25, 25, 26, 27, 29, 30, 32, 34, 37, 42, 55, 89]\n",
            "10000 distinct words\n",
            "Finished data loading: 23792 sentences loaded.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "class Args:\n",
        "    epochs = 12                # 12 אפוקים בלבד\n",
        "    embedding_size = 300\n",
        "    lr = 0.001\n",
        "    batch = 128\n",
        "    task = 'wikisimple'\n",
        "    data = './data'\n",
        "    lstm_capacity = 256\n",
        "    top_words = 10000\n",
        "    limit = None\n",
        "    tb_dir = './runs/words'\n",
        "    seed = -1\n",
        "    extra = None             # None -> 1 שכבת LSTM, 1 -> 2 שכבות\n",
        "\n",
        "options = Args()\n",
        "tbw = SummaryWriter(log_dir=options.tb_dir)\n",
        "\n",
        "if options.seed < 0:\n",
        "    seed_val = random.randint(0, 1000000)\n",
        "    np.random.seed(seed_val)\n",
        "    options.seed = seed_val\n",
        "else:\n",
        "    np.random.seed(options.seed)\n",
        "\n",
        "data_source = os.path.join(util.DIR, 'datasets', 'wikisimple.txt')\n",
        "X, w2i, i2w = util.load_words(data_source, vocab_size=options.top_words, limit=options.limit)\n",
        "\n",
        "X_train, X_temp = train_test_split(X, test_size=0.2, random_state=options.seed)\n",
        "X_val, X_test = train_test_split(X_temp, test_size=0.5, random_state=options.seed)\n",
        "\n",
        "X_train = util.batch_pad(X_train, options.batch, add_eos=True)\n",
        "X_val = util.batch_pad(X_val, options.batch, add_eos=True)\n",
        "X_test = util.batch_pad(X_test, options.batch, add_eos=True)\n",
        "numwords = len(i2w)\n",
        "print(numwords, \"distinct words\")\n",
        "print(\"Finished data loading:\", sum(b.shape[0] for b in X_train), \"sentences loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_HVGrPqdFAvs"
      },
      "outputs": [],
      "source": [
        "def create_lstm_model(extra=None, lr=0.001):\n",
        "    inp = Input(shape=(None,))\n",
        "    x = Embedding(numwords, options.embedding_size)(inp)\n",
        "    h = LSTM(options.lstm_capacity, return_sequences=True)(x)\n",
        "    if extra is not None:\n",
        "        for _ in range(extra):\n",
        "            h = LSTM(options.lstm_capacity, return_sequences=True)(h)\n",
        "    out = TimeDistributed(Dense(numwords, activation='linear'))(h)\n",
        "    model = Model(inp, out)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(lr),\n",
        "                  loss=lambda y_true, y_pred: tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred, from_logits=True))\n",
        "    return model\n",
        "\n",
        "def train_model(model, X_data, direction='forward'):\n",
        "    for epoch in range(options.epochs):\n",
        "        for batch in tqdm(X_data, desc=f\"Epoch {epoch+1}\"):\n",
        "            n, l = batch.shape\n",
        "            if direction == 'backward':\n",
        "                batch_reversed = np.flip(batch, axis=1)\n",
        "                batch_shifted = np.concatenate([np.ones((n, 1)), batch_reversed], axis=1)\n",
        "                batch_out = np.concatenate([batch_reversed, np.zeros((n, 1))], axis=1)\n",
        "            else:\n",
        "                batch_shifted = np.concatenate([np.ones((n, 1)), batch], axis=1)\n",
        "                batch_out = np.concatenate([batch, np.zeros((n, 1))], axis=1)\n",
        "            loss = model.train_on_batch(batch_shifted, batch_out[:, :, None])\n",
        "            tbw.add_scalar('lm/batch_loss', float(loss), epoch)\n",
        "        print(f\"Epoch {epoch+1} loss: {loss}\")\n",
        "\n",
        "def compute_perplexity(model, X_data, direction='forward'):\n",
        "    total_loss = 0.0\n",
        "    total_tokens = 0\n",
        "    for batch in tqdm(X_data, desc=\"Computing Perplexity\"):\n",
        "        n, l = batch.shape\n",
        "        if direction == 'backward':\n",
        "            batch_reversed = np.flip(batch, axis=1)\n",
        "            batch_shifted = np.concatenate([np.ones((n, 1)), batch_reversed], axis=1)\n",
        "            batch_out = np.concatenate([batch_reversed, np.zeros((n, 1))], axis=1)\n",
        "        else:\n",
        "            batch_shifted = np.concatenate([np.ones((n, 1)), batch], axis=1)\n",
        "            batch_out = np.concatenate([batch, np.zeros((n, 1))], axis=1)\n",
        "        loss = model.evaluate(batch_shifted, batch_out[:, :, None], verbose=0)\n",
        "        non_pad = np.sum(batch_out != 0)\n",
        "        total_loss += loss * non_pad\n",
        "        total_tokens += non_pad\n",
        "    avg_loss = total_loss / total_tokens\n",
        "    return np.exp(avg_loss)\n",
        "\n",
        "def sentence_probability(model, sentence, direction='forward'):\n",
        "    tokens = [w2i.get(word, w2i['<UNK>']) for word in sentence.split()]\n",
        "    if direction == 'backward':\n",
        "        tokens = tokens[::-1]\n",
        "    inp_seq = np.array([1] + tokens)  # 1 מייצג <START>\n",
        "    inp_seq = inp_seq[None, :]\n",
        "    logits = model.predict(inp_seq)\n",
        "    prob = 1.0\n",
        "    for i in range(1, inp_seq.shape[1]):\n",
        "        logit_i = logits[0, i-1, :]\n",
        "        exp_logits = np.exp(logit_i - np.max(logit_i))\n",
        "        softmax = exp_logits / np.sum(exp_logits)\n",
        "        prob *= softmax[inp_seq[0, i]]\n",
        "    return prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "EeC5YLjkFCrQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42f2b4c4-a15d-4d99-af7b-5ba62498965b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 1 - 1L forward\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 186/186 [06:30<00:00,  2.10s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 loss: 6.112192153930664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 186/186 [06:17<00:00,  2.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 loss: 5.621982097625732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 186/186 [06:21<00:00,  2.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 loss: 5.318646430969238\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 186/186 [06:11<00:00,  2.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 loss: 5.086594104766846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 186/186 [06:20<00:00,  2.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 loss: 4.891504287719727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 186/186 [06:18<00:00,  2.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 loss: 4.720603942871094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 186/186 [06:11<00:00,  2.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 loss: 4.5683698654174805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 186/186 [06:12<00:00,  2.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 loss: 4.4310832023620605\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 186/186 [06:20<00:00,  2.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 loss: 4.306709289550781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 186/186 [06:12<00:00,  2.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 loss: 4.193889141082764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|██████████| 186/186 [06:10<00:00,  1.99s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 loss: 4.0908966064453125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12: 100%|██████████| 186/186 [06:10<00:00,  1.99s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 loss: 3.9964277744293213\n",
            "Model 1 - 1L forward training complete.\n",
            "Model 2 - 1L backward\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 186/186 [06:15<00:00,  2.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 loss: 5.982174396514893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 186/186 [06:12<00:00,  2.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 loss: 5.528874397277832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 186/186 [06:09<00:00,  1.99s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 loss: 5.243752479553223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 186/186 [06:08<00:00,  1.98s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 loss: 5.015181064605713\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 186/186 [06:10<00:00,  1.99s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 loss: 4.820666790008545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 186/186 [06:08<00:00,  1.98s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 loss: 4.6485395431518555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 186/186 [06:12<00:00,  2.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 loss: 4.495271682739258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 186/186 [06:09<00:00,  1.99s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 loss: 4.356474876403809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 186/186 [06:08<00:00,  1.98s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 loss: 4.228768348693848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 186/186 [06:08<00:00,  1.98s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 loss: 4.11252498626709\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|██████████| 186/186 [06:11<00:00,  2.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 loss: 4.006430149078369\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12: 100%|██████████| 186/186 [06:11<00:00,  2.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 loss: 3.908710241317749\n",
            "Model 2 - 1L backward training complete.\n",
            "Model 3 - 2L forward\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 186/186 [07:08<00:00,  2.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 loss: 6.645418643951416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 186/186 [06:57<00:00,  2.24s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 loss: 6.5245842933654785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 186/186 [06:58<00:00,  2.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 loss: 6.466971397399902\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 186/186 [06:59<00:00,  2.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 loss: 6.402833461761475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 186/186 [07:00<00:00,  2.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 loss: 6.329519748687744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 186/186 [07:01<00:00,  2.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 loss: 6.258840560913086\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 186/186 [06:59<00:00,  2.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 loss: 6.196720123291016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 186/186 [07:00<00:00,  2.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 loss: 6.1404852867126465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 186/186 [06:59<00:00,  2.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 loss: 6.091336727142334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 186/186 [06:57<00:00,  2.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 loss: 6.048396587371826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|██████████| 186/186 [06:59<00:00,  2.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 loss: 6.005643844604492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12: 100%|██████████| 186/186 [06:58<00:00,  2.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 loss: 5.965763092041016\n",
            "Model 3 - 2L forward training complete.\n",
            "Model 4 - 2L backward\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 186/186 [07:07<00:00,  2.30s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 loss: 6.623945236206055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 186/186 [06:58<00:00,  2.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 loss: 6.450170993804932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 186/186 [06:57<00:00,  2.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 loss: 6.380579471588135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 186/186 [06:59<00:00,  2.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 loss: 6.336943626403809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 186/186 [07:00<00:00,  2.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 loss: 6.303666591644287\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 186/186 [06:59<00:00,  2.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 loss: 6.269862174987793\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 186/186 [06:59<00:00,  2.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 loss: 6.235731601715088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 186/186 [06:59<00:00,  2.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 loss: 6.203881740570068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 186/186 [06:58<00:00,  2.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 loss: 6.1813459396362305\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 186/186 [06:58<00:00,  2.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 loss: 6.150386333465576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|██████████| 186/186 [06:57<00:00,  2.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 loss: 6.115967273712158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12: 100%|██████████| 186/186 [06:56<00:00,  2.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 loss: 6.079244136810303\n",
            "Model 4 - 2L backward training complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "models = []\n",
        "model1 = create_lstm_model(extra=None, lr=0.01)      # 1 שכבת LSTM, forward\n",
        "models.append(('Model 1 - 1L forward', model1, 'forward'))\n",
        "model2 = create_lstm_model(extra=None, lr=0.01)      # 1 שכבת LSTM, backward\n",
        "models.append(('Model 2 - 1L backward', model2, 'backward'))\n",
        "model3 = create_lstm_model(extra=1, lr=0.001)        # 2 שכבות LSTM, forward\n",
        "models.append(('Model 3 - 2L forward', model3, 'forward'))\n",
        "model4 = create_lstm_model(extra=1, lr=0.001)        # 2 שכבות LSTM, backward\n",
        "models.append(('Model 4 - 2L backward', model4, 'backward'))\n",
        "\n",
        "for name, model, direction in models:\n",
        "    print(name)\n",
        "    train_model(model, X_train, direction)\n",
        "    print(f\"{name} training complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "pxQYsEh9FEiO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e9389a8-3f27-44af-c349-e3fa02fafc16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing Perplexity: 100%|██████████| 186/186 [03:45<00:00,  1.21s/it]\n",
            "Computing Perplexity: 100%|██████████| 24/24 [00:30<00:00,  1.26s/it]\n",
            "Computing Perplexity: 100%|██████████| 24/24 [00:28<00:00,  1.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 1 - 1L forward - Train Perplexity: 21.80, Val Perplexity: 73.70, Test Perplexity: 68.90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing Perplexity: 100%|██████████| 186/186 [03:45<00:00,  1.21s/it]\n",
            "Computing Perplexity: 100%|██████████| 24/24 [00:30<00:00,  1.25s/it]\n",
            "Computing Perplexity: 100%|██████████| 24/24 [00:28<00:00,  1.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 2 - 1L backward - Train Perplexity: 20.42, Val Perplexity: 75.28, Test Perplexity: 71.11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing Perplexity: 100%|██████████| 186/186 [04:18<00:00,  1.39s/it]\n",
            "Computing Perplexity: 100%|██████████| 24/24 [00:32<00:00,  1.35s/it]\n",
            "Computing Perplexity: 100%|██████████| 24/24 [00:33<00:00,  1.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 3 - 2L forward - Train Perplexity: 279.55, Val Perplexity: 250.00, Test Perplexity: 248.79\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing Perplexity: 100%|██████████| 186/186 [04:08<00:00,  1.34s/it]\n",
            "Computing Perplexity: 100%|██████████| 24/24 [00:32<00:00,  1.35s/it]\n",
            "Computing Perplexity: 100%|██████████| 24/24 [00:31<00:00,  1.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 4 - 2L backward - Train Perplexity: 316.83, Val Perplexity: 310.18, Test Perplexity: 308.58\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step\n",
            "Sentence probability (forward) for 'I love cupcakes': 1.843243473559138e-08\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step\n",
            "Sentence probability (backward) for 'I love cupcakes': 6.643910378335513e-09\n"
          ]
        }
      ],
      "source": [
        "for name, model, direction in models:\n",
        "    train_ppl = compute_perplexity(model, X_train, direction)\n",
        "    val_ppl = compute_perplexity(model, X_val, direction)\n",
        "    test_ppl = compute_perplexity(model, X_test, direction)\n",
        "    print(f\"{name} - Train Perplexity: {train_ppl:.2f}, Val Perplexity: {val_ppl:.2f}, Test Perplexity: {test_ppl:.2f}\")\n",
        "\n",
        "sentence = \"I love cupcakes\"\n",
        "print(\"Sentence probability (forward) for 'I love cupcakes':\", sentence_probability(model1, sentence, direction='forward'))\n",
        "print(\"Sentence probability (backward) for 'I love cupcakes':\", sentence_probability(model2, sentence, direction='backward'))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
